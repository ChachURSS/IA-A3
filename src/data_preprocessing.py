"""
Module de prÃ©traitement des donnÃ©es.

Ce module contient les fonctions pour le nettoyage des donnÃ©es,
la gestion des valeurs manquantes, l'encodage des variables catÃ©gorielles,
et la normalisation des features numÃ©riques.
"""

import pandas as pd
import numpy as np
from typing import Tuple, List, Optional, Dict
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
import warnings

warnings.filterwarnings('ignore')


def handle_missing_values(
    df: pd.DataFrame,
    strategy: str = 'median',
    categorical_strategy: str = 'mode'
) -> pd.DataFrame:
    """
    GÃ¨re les valeurs manquantes dans le DataFrame.
    
    Args:
        df: DataFrame Ã  traiter.
        strategy: StratÃ©gie pour les colonnes numÃ©riques ('mean', 'median', 'mode').
        categorical_strategy: StratÃ©gie pour les colonnes catÃ©gorielles ('mode', 'constant').
        
    Returns:
        DataFrame avec les valeurs manquantes traitÃ©es.
    """
    df_clean = df.copy()
    
    print("ðŸ”§ TRAITEMENT DES VALEURS MANQUANTES")
    print("-" * 40)
    
    # Colonnes numÃ©riques
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()
    
    # Colonnes catÃ©gorielles
    categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # Traiter les colonnes numÃ©riques
    for col in numeric_cols:
        missing = df_clean[col].isnull().sum()
        if missing > 0:
            if strategy == 'mean':
                fill_value = df_clean[col].mean()
            elif strategy == 'median':
                fill_value = df_clean[col].median()
            else:  # mode
                fill_value = df_clean[col].mode()[0] if len(df_clean[col].mode()) > 0 else 0
            
            df_clean[col].fillna(fill_value, inplace=True)
            print(f"  â€¢ {col}: {missing} NA â†’ remplacÃ©s par {strategy} ({fill_value:.2f})")
    
    # Traiter les colonnes catÃ©gorielles
    for col in categorical_cols:
        missing = df_clean[col].isnull().sum()
        if missing > 0:
            if categorical_strategy == 'mode':
                fill_value = df_clean[col].mode()[0] if len(df_clean[col].mode()) > 0 else 'Unknown'
            else:
                fill_value = 'Unknown'
            
            df_clean[col].fillna(fill_value, inplace=True)
            print(f"  â€¢ {col}: {missing} NA â†’ remplacÃ©s par '{fill_value}'")
    
    remaining_na = df_clean.isnull().sum().sum()
    print(f"\nâœ… Valeurs manquantes restantes: {remaining_na}")
    
    return df_clean


def encode_target_variable(df: pd.DataFrame, target_col: str = 'Attrition') -> pd.DataFrame:
    """
    Encode la variable cible (Attrition) en valeurs numÃ©riques.
    
    Args:
        df: DataFrame contenant la variable cible.
        target_col: Nom de la colonne cible.
        
    Returns:
        DataFrame avec la variable cible encodÃ©e.
    """
    df_encoded = df.copy()
    
    if target_col not in df_encoded.columns:
        print(f"âš ï¸ Colonne '{target_col}' non trouvÃ©e")
        return df_encoded
    
    # Encoder Yes/No en 1/0
    if df_encoded[target_col].dtype == 'object':
        df_encoded[target_col] = df_encoded[target_col].map({'Yes': 1, 'No': 0})
        print(f"âœ… Variable cible '{target_col}' encodÃ©e: Yes=1, No=0")
    
    return df_encoded


def encode_categorical_features(
    df: pd.DataFrame,
    method: str = 'label',
    exclude_cols: List[str] = None
) -> Tuple[pd.DataFrame, Dict[str, LabelEncoder]]:
    """
    Encode les variables catÃ©gorielles.
    
    Args:
        df: DataFrame Ã  encoder.
        method: MÃ©thode d'encodage ('label' ou 'onehot').
        exclude_cols: Colonnes Ã  exclure de l'encodage.
        
    Returns:
        Tuple (DataFrame encodÃ©, dictionnaire des encodeurs).
    """
    if exclude_cols is None:
        exclude_cols = ['EmployeeID', 'EmployeeId']
    
    df_encoded = df.copy()
    encoders = {}
    
    # Identifier les colonnes catÃ©gorielles
    categorical_cols = df_encoded.select_dtypes(include=['object']).columns.tolist()
    categorical_cols = [col for col in categorical_cols if col not in exclude_cols]
    
    print(f"\nðŸ·ï¸ ENCODAGE DES VARIABLES CATÃ‰GORIELLES ({method})")
    print("-" * 40)
    
    if method == 'label':
        for col in categorical_cols:
            le = LabelEncoder()
            df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
            encoders[col] = le
            print(f"  â€¢ {col}: {len(le.classes_)} classes â†’ {list(le.classes_)[:5]}...")
    
    elif method == 'onehot':
        for col in categorical_cols:
            dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=True)
            df_encoded = pd.concat([df_encoded.drop(col, axis=1), dummies], axis=1)
            print(f"  â€¢ {col}: {len(dummies.columns)} nouvelles colonnes crÃ©Ã©es")
    
    print(f"\nâœ… {len(categorical_cols)} colonnes catÃ©gorielles encodÃ©es")
    
    return df_encoded, encoders


def scale_numeric_features(
    df: pd.DataFrame,
    method: str = 'standard',
    exclude_cols: List[str] = None
) -> Tuple[pd.DataFrame, object]:
    """
    Normalise/Standardise les features numÃ©riques.
    
    Args:
        df: DataFrame Ã  normaliser.
        method: MÃ©thode de normalisation ('standard' ou 'minmax').
        exclude_cols: Colonnes Ã  exclure de la normalisation.
        
    Returns:
        Tuple (DataFrame normalisÃ©, scaler utilisÃ©).
    """
    if exclude_cols is None:
        exclude_cols = ['EmployeeID', 'EmployeeId', 'Attrition']
    
    df_scaled = df.copy()
    
    # Identifier les colonnes numÃ©riques Ã  normaliser
    numeric_cols = df_scaled.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [col for col in numeric_cols if col not in exclude_cols]
    
    print(f"\nðŸ“ NORMALISATION DES FEATURES ({method})")
    print("-" * 40)
    
    if method == 'standard':
        scaler = StandardScaler()
    else:
        scaler = MinMaxScaler()
    
    if numeric_cols:
        df_scaled[numeric_cols] = scaler.fit_transform(df_scaled[numeric_cols])
        print(f"  â€¢ {len(numeric_cols)} colonnes normalisÃ©es")
        print(f"  â€¢ Colonnes: {numeric_cols[:5]}..." if len(numeric_cols) > 5 else f"  â€¢ Colonnes: {numeric_cols}")
    
    return df_scaled, scaler


def prepare_train_test_split(
    df: pd.DataFrame,
    target_col: str = 'Attrition',
    test_size: float = 0.2,
    random_state: int = 42,
    stratify: bool = True
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    PrÃ©pare les ensembles d'entraÃ®nement et de test.
    
    Args:
        df: DataFrame prÃ©parÃ©.
        target_col: Nom de la colonne cible.
        test_size: Proportion de l'ensemble de test.
        random_state: Graine alÃ©atoire pour la reproductibilitÃ©.
        stratify: Si True, stratifie sur la variable cible.
        
    Returns:
        Tuple (X_train, X_test, y_train, y_test).
    """
    print(f"\nâœ‚ï¸ SPLIT TRAIN/TEST")
    print("-" * 40)
    
    if target_col not in df.columns:
        raise ValueError(f"Colonne cible '{target_col}' non trouvÃ©e dans le DataFrame")
    
    # SÃ©parer features et target
    X = df.drop(columns=[target_col, 'EmployeeID'] if 'EmployeeID' in df.columns else [target_col])
    y = df[target_col]
    
    # Split
    stratify_param = y if stratify else None
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state,
        stratify=stratify_param
    )
    
    print(f"  â€¢ Ensemble d'entraÃ®nement: {len(X_train)} Ã©chantillons ({(1-test_size)*100:.0f}%)")
    print(f"  â€¢ Ensemble de test: {len(X_test)} Ã©chantillons ({test_size*100:.0f}%)")
    
    if stratify:
        train_ratio = y_train.mean()
        test_ratio = y_test.mean()
        print(f"  â€¢ Taux d'attrition (train): {train_ratio*100:.1f}%")
        print(f"  â€¢ Taux d'attrition (test): {test_ratio*100:.1f}%")
    
    return X_train, X_test, y_train, y_test


def preprocess_pipeline(
    df: pd.DataFrame,
    target_col: str = 'Attrition',
    missing_strategy: str = 'median',
    encoding_method: str = 'label',
    scaling_method: str = 'standard',
    test_size: float = 0.2,
    random_state: int = 42
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, Dict]:
    """
    Pipeline complet de prÃ©traitement des donnÃ©es.
    
    Args:
        df: DataFrame brut.
        target_col: Nom de la colonne cible.
        missing_strategy: StratÃ©gie pour les valeurs manquantes.
        encoding_method: MÃ©thode d'encodage des catÃ©gories.
        scaling_method: MÃ©thode de normalisation.
        test_size: Proportion de l'ensemble de test.
        random_state: Graine alÃ©atoire.
        
    Returns:
        Tuple (X_train, X_test, y_train, y_test, metadata).
    """
    print("=" * 60)
    print("ðŸ”„ PIPELINE DE PRÃ‰TRAITEMENT")
    print("=" * 60)
    
    metadata = {}
    
    # 1. Gestion des valeurs manquantes
    df_clean = handle_missing_values(df, strategy=missing_strategy)
    
    # 2. Encodage de la variable cible
    if target_col in df_clean.columns:
        df_clean = encode_target_variable(df_clean, target_col)
    
    # 3. Encodage des variables catÃ©gorielles
    df_encoded, encoders = encode_categorical_features(df_clean, method=encoding_method)
    metadata['encoders'] = encoders
    
    # 4. Normalisation (optionnel, fait avant le split pour avoir les stats)
    df_scaled, scaler = scale_numeric_features(df_encoded, method=scaling_method)
    metadata['scaler'] = scaler
    
    # 5. Split train/test
    if target_col in df_scaled.columns:
        X_train, X_test, y_train, y_test = prepare_train_test_split(
            df_scaled, target_col, test_size, random_state
        )
    else:
        print(f"âš ï¸ Variable cible '{target_col}' non trouvÃ©e. Retour du dataset complet.")
        return df_scaled, None, None, None, metadata
    
    print("\n" + "=" * 60)
    print("âœ… PRÃ‰TRAITEMENT TERMINÃ‰")
    print("=" * 60)
    
    return X_train, X_test, y_train, y_test, metadata


def get_feature_types(df: pd.DataFrame) -> Dict[str, List[str]]:
    """
    Identifie les types de features dans le DataFrame.
    
    Args:
        df: DataFrame Ã  analyser.
        
    Returns:
        Dictionnaire avec les listes de colonnes par type.
    """
    return {
        'numeric': df.select_dtypes(include=[np.number]).columns.tolist(),
        'categorical': df.select_dtypes(include=['object', 'category']).columns.tolist(),
        'boolean': df.select_dtypes(include=['bool']).columns.tolist()
    }
