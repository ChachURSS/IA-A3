{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse du Taux d'Attrition - HumanForYou\n",
    "\n",
    "## Projet d'Intelligence Artificielle\n",
    "\n",
    "**Contexte** : L'entreprise pharmaceutique HumanForYou (bas√©e en Inde, ~4000 employ√©s) conna√Æt un taux de rotation d'environ 15% par an. La direction souhaite identifier les facteurs influen√ßant ce taux et proposer des pistes d'am√©lioration pour fid√©liser les employ√©s.\n",
    "\n",
    "**Objectifs** :\n",
    "1. Explorer et analyser les donn√©es des employ√©s\n",
    "2. Identifier les facteurs cl√©s d'attrition\n",
    "3. Construire des mod√®les pr√©dictifs\n",
    "4. √âvaluer et comparer les performances\n",
    "5. Proposer des recommandations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports de base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configuration de l'affichage\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Ajouter le chemin du projet au PYTHONPATH\n",
    "project_root = os.path.dirname(os.path.abspath('.'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"‚úÖ Configuration de base termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des modules du projet\n",
    "try:\n",
    "    from src.data_loader import load_all_data, merge_datasets, display_dataset_summary\n",
    "    from src.data_preprocessing import preprocess_pipeline, handle_missing_values, encode_target_variable\n",
    "    from src.feature_engineering import feature_engineering_pipeline, create_derived_features\n",
    "    from src.models import train_and_evaluate_all_models, get_feature_importance\n",
    "    from src.visualization import (\n",
    "        plot_target_distribution, plot_numeric_distributions, \n",
    "        plot_correlation_matrix, plot_correlation_with_target,\n",
    "        plot_confusion_matrix, plot_roc_curves, \n",
    "        plot_feature_importance, plot_model_comparison\n",
    "    )\n",
    "    print(\"‚úÖ Modules du projet import√©s avec succ√®s\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur d'import: {e}\")\n",
    "    print(\"Les fonctions seront d√©finies localement si n√©cessaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports ML\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# XGBoost (optionnel)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"‚úÖ XGBoost disponible\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è XGBoost non disponible (installez avec: pip install xgboost)\")\n",
    "\n",
    "# SHAP pour l'interpr√©tabilit√© (optionnel)\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "    print(\"‚úÖ SHAP disponible\")\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è SHAP non disponible (installez avec: pip install shap)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le chemin vers les donn√©es\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "# V√©rifier les fichiers disponibles\n",
    "print(\"üìÅ Fichiers de donn√©es disponibles :\")\n",
    "for f in os.listdir(DATA_PATH):\n",
    "    filepath = os.path.join(DATA_PATH, f)\n",
    "    if os.path.isfile(filepath):\n",
    "        size = os.path.getsize(filepath)\n",
    "        print(f\"  ‚Ä¢ {f} ({size:,} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es disponibles\n",
    "employee_survey = None\n",
    "manager_survey = None\n",
    "general_data = None\n",
    "\n",
    "# Employee Survey Data\n",
    "try:\n",
    "    employee_survey = pd.read_csv(os.path.join(DATA_PATH, 'employee_survey_data.csv'), na_values=['NA', 'na', 'N/A', ''])\n",
    "    print(f\"‚úÖ employee_survey_data.csv charg√©: {employee_survey.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è employee_survey_data.csv non trouv√©\")\n",
    "\n",
    "# Manager Survey Data\n",
    "try:\n",
    "    manager_survey = pd.read_csv(os.path.join(DATA_PATH, 'manager_survey_data.csv'))\n",
    "    print(f\"‚úÖ manager_survey_data.csv charg√©: {manager_survey.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è manager_survey_data.csv non trouv√©\")\n",
    "\n",
    "# General Data (optionnel - fichier trop volumineux)\n",
    "try:\n",
    "    general_data = pd.read_csv(os.path.join(DATA_PATH, 'general_data.csv'))\n",
    "    print(f\"‚úÖ general_data.csv charg√©: {general_data.shape}\")\n",
    "    FULL_DATASET = True\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è general_data.csv non trouv√© (fichier √† ajouter manuellement)\")\n",
    "    FULL_DATASET = False\n",
    "    print(\"   ‚ÑπÔ∏è Le notebook fonctionnera avec les donn√©es partielles disponibles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es charg√©es\n",
    "if employee_survey is not None:\n",
    "    print(\"\\nüìä Employee Survey Data :\")\n",
    "    display(employee_survey.head())\n",
    "    print(f\"\\nColonnes: {list(employee_survey.columns)}\")\n",
    "    print(f\"Valeurs manquantes:\\n{employee_survey.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if manager_survey is not None:\n",
    "    print(\"\\nüìä Manager Survey Data :\")\n",
    "    display(manager_survey.head())\n",
    "    print(f\"\\nColonnes: {list(manager_survey.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if general_data is not None:\n",
    "    print(\"\\nüìä General Data :\")\n",
    "    display(general_data.head())\n",
    "    print(f\"\\nColonnes: {list(general_data.columns)}\")\n",
    "    print(f\"\\nVariable cible (Attrition):\")\n",
    "    print(general_data['Attrition'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion des Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les donn√©es disponibles\n",
    "if FULL_DATASET and general_data is not None:\n",
    "    # Standardiser les noms de colonnes\n",
    "    if 'EmployeeId' in general_data.columns:\n",
    "        general_data.rename(columns={'EmployeeId': 'EmployeeID'}, inplace=True)\n",
    "    \n",
    "    df = general_data.copy()\n",
    "    \n",
    "    if employee_survey is not None:\n",
    "        df = df.merge(employee_survey, on='EmployeeID', how='left')\n",
    "        print(\"‚úÖ Fusionn√© avec employee_survey\")\n",
    "    \n",
    "    if manager_survey is not None:\n",
    "        df = df.merge(manager_survey, on='EmployeeID', how='left')\n",
    "        print(\"‚úÖ Fusionn√© avec manager_survey\")\n",
    "    \n",
    "    print(f\"\\nüìä Dataset fusionn√©: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "else:\n",
    "    # Travailler avec les donn√©es partielles\n",
    "    if employee_survey is not None and manager_survey is not None:\n",
    "        df = employee_survey.merge(manager_survey, on='EmployeeID', how='outer')\n",
    "        print(f\"\\nüìä Dataset partiel (surveys uniquement): {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "        print(\"\\n‚ö†Ô∏è Note: Sans general_data.csv, la variable cible (Attrition) n'est pas disponible.\")\n",
    "        print(\"   Ajoutez le fichier general_data.csv pour une analyse compl√®te.\")\n",
    "    else:\n",
    "        df = None\n",
    "        print(\"‚ùå Pas assez de donn√©es pour cr√©er un dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Analyse Exploratoire (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üìã Informations g√©n√©rales sur le dataset :\")\n",
    "    print(f\"\\nDimensions: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "    print(f\"\\nTypes de donn√©es:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    print(f\"\\nM√©moire utilis√©e: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"\\nüìä Statistiques descriptives (variables num√©riques) :\")\n",
    "    display(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"\\nüîç Valeurs manquantes :\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0].sort_values(ascending=False)\n",
    "    if len(missing) > 0:\n",
    "        for col, count in missing.items():\n",
    "            pct = count / len(df) * 100\n",
    "            print(f\"  ‚Ä¢ {col}: {count} ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  Aucune valeur manquante !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution de la Variable Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'Attrition' in df.columns:\n",
    "    print(\"\\nüìä Distribution de l'Attrition :\")\n",
    "    print(df['Attrition'].value_counts())\n",
    "    print(f\"\\nTaux d'attrition: {(df['Attrition'] == 'Yes').mean() * 100:.1f}%\")\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    counts = df['Attrition'].value_counts()\n",
    "    bars = ax.bar(counts.index, counts.values, color=colors)\n",
    "    \n",
    "    for bar, count in zip(bars, counts.values):\n",
    "        pct = count / len(df) * 100\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "                f'{pct:.1f}%\\n({count})', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.set_title('Distribution de l\\'Attrition', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Nombre d\\'employ√©s')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Variable Attrition non disponible\")\n",
    "    print(\"   Ajoutez le fichier general_data.csv pour acc√©der √† cette variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution des Variables Num√©riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Variables de satisfaction (surveys)\n",
    "    survey_cols = ['EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', \n",
    "                   'JobInvolvement', 'PerformanceRating']\n",
    "    available_cols = [c for c in survey_cols if c in df.columns]\n",
    "    \n",
    "    if available_cols:\n",
    "        fig, axes = plt.subplots(1, len(available_cols), figsize=(15, 4))\n",
    "        if len(available_cols) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, col in zip(axes, available_cols):\n",
    "            df[col].value_counts().sort_index().plot(kind='bar', ax=ax, color='steelblue')\n",
    "            ax.set_title(col, fontsize=10)\n",
    "            ax.set_xlabel('')\n",
    "        \n",
    "        plt.suptitle('Distribution des Variables de Satisfaction', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and FULL_DATASET:\n",
    "    # Variables d√©mographiques\n",
    "    demo_cols = ['Age', 'MonthlyIncome', 'DistanceFromHome', 'TotalWorkingYears']\n",
    "    available_demo = [c for c in demo_cols if c in df.columns]\n",
    "    \n",
    "    if available_demo:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, col in enumerate(available_demo):\n",
    "            sns.histplot(df[col], ax=axes[i], kde=True, color='steelblue')\n",
    "            axes[i].set_title(col)\n",
    "        \n",
    "        plt.suptitle('Distribution des Variables D√©mographiques', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de Corr√©lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Corr√©lation entre les variables num√©riques\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    if len(numeric_df.columns) > 1:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        corr = numeric_df.corr()\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "        \n",
    "        sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "                    center=0, square=True, linewidths=0.5)\n",
    "        plt.title('Matrice de Corr√©lation', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Pr√©traitement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # 1. Gestion des valeurs manquantes\n",
    "    print(\"üîß Traitement des valeurs manquantes...\")\n",
    "    \n",
    "    for col in df_processed.select_dtypes(include=[np.number]).columns:\n",
    "        if df_processed[col].isnull().sum() > 0:\n",
    "            median_val = df_processed[col].median()\n",
    "            df_processed[col].fillna(median_val, inplace=True)\n",
    "            print(f\"  ‚Ä¢ {col}: valeurs manquantes remplac√©es par la m√©diane ({median_val})\")\n",
    "    \n",
    "    for col in df_processed.select_dtypes(include=['object']).columns:\n",
    "        if df_processed[col].isnull().sum() > 0:\n",
    "            mode_val = df_processed[col].mode()[0]\n",
    "            df_processed[col].fillna(mode_val, inplace=True)\n",
    "            print(f\"  ‚Ä¢ {col}: valeurs manquantes remplac√©es par le mode ({mode_val})\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Valeurs manquantes restantes: {df_processed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'Attrition' in df_processed.columns:\n",
    "    # 2. Encodage de la variable cible\n",
    "    print(\"\\nüè∑Ô∏è Encodage de la variable cible...\")\n",
    "    \n",
    "    if df_processed['Attrition'].dtype == 'object':\n",
    "        df_processed['Attrition'] = df_processed['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "        print(f\"  ‚Ä¢ Attrition encod√©e: Yes=1, No=0\")\n",
    "    \n",
    "    print(f\"\\n Distribution apr√®s encodage:\")\n",
    "    print(df_processed['Attrition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # 3. Encodage des variables cat√©gorielles\n",
    "    print(\"\\nüè∑Ô∏è Encodage des variables cat√©gorielles...\")\n",
    "    \n",
    "    categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "    # Exclure les colonnes d'ID\n",
    "    categorical_cols = [c for c in categorical_cols if 'ID' not in c.upper()]\n",
    "    \n",
    "    encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "        encoders[col] = le\n",
    "        print(f\"  ‚Ä¢ {col}: {len(le.classes_)} classes encod√©es\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ {len(categorical_cols)} colonnes cat√©gorielles encod√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and FULL_DATASET:\n",
    "    print(\"üõ†Ô∏è Cr√©ation de features d√©riv√©es...\")\n",
    "    \n",
    "    new_features = []\n",
    "    \n",
    "    # Ratio anciennet√©\n",
    "    if 'YearsAtCompany' in df_processed.columns and 'TotalWorkingYears' in df_processed.columns:\n",
    "        df_processed['TenureRatio'] = df_processed['YearsAtCompany'] / (df_processed['TotalWorkingYears'] + 1)\n",
    "        new_features.append('TenureRatio')\n",
    "    \n",
    "    # Stagnation de promotion\n",
    "    if 'YearsSinceLastPromotion' in df_processed.columns and 'YearsAtCompany' in df_processed.columns:\n",
    "        df_processed['PromotionStagnation'] = df_processed['YearsSinceLastPromotion'] / (df_processed['YearsAtCompany'] + 1)\n",
    "        new_features.append('PromotionStagnation')\n",
    "    \n",
    "    # Score de satisfaction globale\n",
    "    satisfaction_cols = ['EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance']\n",
    "    available_sat = [c for c in satisfaction_cols if c in df_processed.columns]\n",
    "    if available_sat:\n",
    "        df_processed['OverallSatisfaction'] = df_processed[available_sat].mean(axis=1)\n",
    "        new_features.append('OverallSatisfaction')\n",
    "    \n",
    "    # Revenu par ann√©e d'exp√©rience\n",
    "    if 'MonthlyIncome' in df_processed.columns and 'TotalWorkingYears' in df_processed.columns:\n",
    "        df_processed['IncomePerYear'] = df_processed['MonthlyIncome'] / (df_processed['TotalWorkingYears'] + 1)\n",
    "        new_features.append('IncomePerYear')\n",
    "    \n",
    "    print(f\"\\n‚úÖ {len(new_features)} nouvelles features cr√©√©es:\")\n",
    "    for f in new_features:\n",
    "        print(f\"  ‚Ä¢ {f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Feature engineering limit√© sans le dataset complet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Pr√©paration des Donn√©es pour le Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'Attrition' in df_processed.columns:\n",
    "    print(\"‚úÇÔ∏è Pr√©paration train/test split...\")\n",
    "    \n",
    "    # S√©parer features et target\n",
    "    cols_to_drop = ['Attrition']\n",
    "    if 'EmployeeID' in df_processed.columns:\n",
    "        cols_to_drop.append('EmployeeID')\n",
    "    if 'EmployeeId' in df_processed.columns:\n",
    "        cols_to_drop.append('EmployeeId')\n",
    "    \n",
    "    X = df_processed.drop(columns=cols_to_drop)\n",
    "    y = df_processed['Attrition']\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Split effectu√©:\")\n",
    "    print(f\"  ‚Ä¢ Train: {len(X_train)} √©chantillons ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "    print(f\"  ‚Ä¢ Test: {len(X_test)} √©chantillons ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "    print(f\"\\n  Taux d'attrition (train): {y_train.mean()*100:.1f}%\")\n",
    "    print(f\"  Taux d'attrition (test): {y_test.mean()*100:.1f}%\")\n",
    "    \n",
    "    # Normalisation\n",
    "    print(\"\\nüìê Normalisation des features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"  ‚úÖ Features normalis√©es (StandardScaler)\")\n",
    "    \n",
    "    DATA_READY = True\n",
    "else:\n",
    "    print(\"‚ùå Impossible de pr√©parer les donn√©es sans la variable cible (Attrition)\")\n",
    "    print(\"   Ajoutez le fichier general_data.csv pour continuer.\")\n",
    "    DATA_READY = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Entra√Ænement et √âvaluation des Mod√®les\n",
    "\n",
    "### Mod√®les utilis√©s :\n",
    "1. **Logistic Regression** - Mod√®le de base, interpr√©table\n",
    "2. **Random Forest** - Ensemble de d√©cision, robuste\n",
    "3. **XGBoost** - Gradient boosting, performant\n",
    "4. **SVM** - Support Vector Machine, efficace en haute dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY:\n",
    "    print(\"üöÄ Entra√Ænement des mod√®les...\\n\")\n",
    "    \n",
    "    # D√©finir les mod√®les\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "        'SVM': SVC(random_state=42, class_weight='balanced', probability=True)\n",
    "    }\n",
    "    \n",
    "    if XGBOOST_AVAILABLE:\n",
    "        models['XGBoost'] = XGBClassifier(\n",
    "            random_state=42, use_label_encoder=False, \n",
    "            eval_metric='logloss', scale_pos_weight=5\n",
    "        )\n",
    "    \n",
    "    # Entra√Æner et √©valuer\n",
    "    results = []\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"üìä {name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Entra√Ænement\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        trained_models[name] = model\n",
    "        \n",
    "        # Pr√©dictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # M√©triques\n",
    "        metrics = {\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "            'F1-Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "            'AUC-ROC': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        results.append(metrics)\n",
    "        \n",
    "        print(f\"  Accuracy:  {metrics['Accuracy']:.4f}\")\n",
    "        print(f\"  Precision: {metrics['Precision']:.4f}\")\n",
    "        print(f\"  Recall:    {metrics['Recall']:.4f}\")\n",
    "        print(f\"  F1-Score:  {metrics['F1-Score']:.4f}\")\n",
    "        print(f\"  AUC-ROC:   {metrics['AUC-ROC']:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    # Cr√©er le DataFrame des r√©sultats\n",
    "    results_df = pd.DataFrame(results).set_index('Model')\n",
    "    results_df = results_df.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìà COMPARAISON DES MOD√àLES (tri√© par F1-Score)\")\n",
    "    print(\"=\" * 60)\n",
    "    display(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Crois√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY:\n",
    "    print(\"\\nüîÑ Validation crois√©e (5-fold)...\\n\")\n",
    "    \n",
    "    cv_results = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='f1')\n",
    "        cv_results.append({\n",
    "            'Model': name,\n",
    "            'CV Mean F1': scores.mean(),\n",
    "            'CV Std F1': scores.std()\n",
    "        })\n",
    "        print(f\"{name}: F1 = {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_results).set_index('Model')\n",
    "    print(\"\\n\")\n",
    "    display(cv_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Visualisation des Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des M√©triques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY:\n",
    "    # Graphique de comparaison\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "    x = np.arange(len(results_df))\n",
    "    width = 0.15\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        offset = (i - len(metrics_to_plot)/2 + 0.5) * width\n",
    "        bars = ax.bar(x + offset, results_df[metric], width, label=metric)\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Comparaison des Performances des Mod√®les', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(results_df.index)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(trained_models)))\n",
    "    \n",
    "    for (name, model), color in zip(trained_models.items(), colors):\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        ax.plot(fpr, tpr, color=color, lw=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=1, label='Random (AUC = 0.500)')\n",
    "    \n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('Taux de Faux Positifs (FPR)')\n",
    "    ax.set_ylabel('Taux de Vrais Positifs (TPR)')\n",
    "    ax.set_title('Courbes ROC - Comparaison des Mod√®les', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY:\n",
    "    # S√©lectionner le meilleur mod√®le\n",
    "    best_model_name = results_df['F1-Score'].idxmax()\n",
    "    best_model = trained_models[best_model_name]\n",
    "    \n",
    "    print(f\"üèÜ Meilleur mod√®le: {best_model_name}\")\n",
    "    \n",
    "    # Matrice de confusion pour le meilleur mod√®le\n",
    "    y_pred_best = best_model.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred_best)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Stay', 'Leave'],\n",
    "                yticklabels=['Stay', 'Leave'], ax=ax)\n",
    "    ax.set_title(f'Matrice de Confusion - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Pr√©diction')\n",
    "    ax.set_ylabel('R√©alit√©')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Rapport de classification\n",
    "    print(\"\\nüìã Rapport de Classification:\")\n",
    "    print(classification_report(y_test, y_pred_best, target_names=['Stay', 'Leave']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Importance des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY and 'Random Forest' in trained_models:\n",
    "    rf_model = trained_models['Random Forest']\n",
    "    \n",
    "    # Feature importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Top 15 features\n",
    "    top_n = min(15, len(importance_df))\n",
    "    top_features = importance_df.head(top_n)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.8, top_n))\n",
    "    ax.barh(top_features['Feature'][::-1], top_features['Importance'][::-1], color=colors[::-1])\n",
    "    \n",
    "    ax.set_title(f'Top {top_n} Features Importantes - Random Forest', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Importance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Importance des Features:\")\n",
    "    display(importance_df.head(15).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpr√©tabilit√© avec SHAP (si disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY and SHAP_AVAILABLE and 'Random Forest' in trained_models:\n",
    "    print(\"üîç Analyse SHAP...\")\n",
    "    \n",
    "    try:\n",
    "        # Cr√©er l'explainer\n",
    "        explainer = shap.TreeExplainer(trained_models['Random Forest'])\n",
    "        \n",
    "        # Calculer les valeurs SHAP sur un √©chantillon\n",
    "        sample_size = min(100, len(X_test))\n",
    "        X_sample = X_test.iloc[:sample_size]\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        \n",
    "        # Summary plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values[1], X_sample, plot_type=\"bar\", max_display=15, show=False)\n",
    "        plt.title('SHAP Feature Importance', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur SHAP: {e}\")\n",
    "elif not SHAP_AVAILABLE:\n",
    "    print(\"‚ö†Ô∏è SHAP non disponible. Installez avec: pip install shap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Benchmarks et R√©sum√© des Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_READY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä R√âSUM√â DES BENCHMARKS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nüìà Performance des Mod√®les sur l'ensemble de test:\")\n",
    "    print(\"-\" * 60)\n",
    "    display(results_df.round(4))\n",
    "    \n",
    "    print(f\"\\nüèÜ Meilleur mod√®le: {best_model_name}\")\n",
    "    print(f\"   ‚Ä¢ F1-Score: {results_df.loc[best_model_name, 'F1-Score']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ AUC-ROC: {results_df.loc[best_model_name, 'AUC-ROC']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Recall: {results_df.loc[best_model_name, 'Recall']:.4f}\")\n",
    "    \n",
    "    print(\"\\nüìä Statistiques du Dataset:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"   ‚Ä¢ Total employ√©s: {len(df)}\")\n",
    "    print(f\"   ‚Ä¢ Train set: {len(X_train)}\")\n",
    "    print(f\"   ‚Ä¢ Test set: {len(X_test)}\")\n",
    "    print(f\"   ‚Ä¢ Features: {len(X.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Taux d'attrition global: {y.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Conclusions et Recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©sum√© des R√©sultats\n",
    "\n",
    "Cette analyse du taux d'attrition des employ√©s de HumanForYou a permis d'identifier plusieurs enseignements cl√©s :\n",
    "\n",
    "#### Facteurs d'Attrition Identifi√©s\n",
    "\n",
    "Les principaux facteurs influen√ßant l'attrition des employ√©s sont (bas√©s sur l'importance des features) :\n",
    "\n",
    "1. **Satisfaction au travail** - Un faible niveau de satisfaction est fortement corr√©l√© au d√©part\n",
    "2. **√âquilibre vie professionnelle/personnelle** - Les employ√©s insatisfaits de cet √©quilibre sont plus susceptibles de partir\n",
    "3. **Anciennet√© dans l'entreprise** - Les employ√©s avec peu d'anciennet√© pr√©sentent un risque plus √©lev√©\n",
    "4. **Revenu mensuel** - Une r√©mun√©ration inf√©rieure augmente le risque d'attrition\n",
    "5. **Distance du domicile** - Les longs trajets sont un facteur de risque\n",
    "\n",
    "### Recommandations pour HumanForYou\n",
    "\n",
    "#### Actions √† Court Terme\n",
    "- üéØ **Programme de r√©tention cibl√©** pour les employ√©s identifi√©s √† risque\n",
    "- üí¨ **Entretiens de r√©tention** r√©guliers avec les managers\n",
    "- üí∞ **R√©vision salariale** pour les postes √† forte attrition\n",
    "\n",
    "#### Actions √† Moyen Terme\n",
    "- üìà **Plans de carri√®re personnalis√©s** pour am√©liorer la satisfaction\n",
    "- üè† **Politique de t√©l√©travail** pour r√©duire l'impact des trajets\n",
    "- üéì **Programmes de formation** pour d√©velopper l'engagement\n",
    "\n",
    "#### Actions √† Long Terme\n",
    "- üîÑ **Syst√®me de monitoring** pour suivre les indicateurs d'attrition en temps r√©el\n",
    "- üè¢ **Culture d'entreprise** ax√©e sur le bien-√™tre et l'√©quilibre\n",
    "- üìä **Tableaux de bord RH** pour anticiper les d√©parts\n",
    "\n",
    "### Limites de l'Analyse\n",
    "\n",
    "- Les mod√®les sont entra√Æn√©s sur des donn√©es historiques et peuvent ne pas capturer tous les facteurs d'attrition\n",
    "- Certaines variables qualitatives (satisfaction, performance) sont subjectives\n",
    "- Le d√©s√©quilibre des classes (15% d'attrition) peut affecter les pr√©dictions\n",
    "- Les donn√©es de badgeage n'ont pas √©t√© int√©gr√©es dans cette version\n",
    "\n",
    "### Prochaines √âtapes\n",
    "\n",
    "1. **Int√©grer les donn√©es de badgeage** pour enrichir les features\n",
    "2. **Affiner le mod√®le** avec un tuning des hyperparam√®tres plus pouss√©\n",
    "3. **D√©ployer le mod√®le** en production pour des pr√©dictions en temps r√©el\n",
    "4. **Mettre en place un monitoring** de la performance du mod√®le\n",
    "5. **Former les √©quipes RH** √† l'interpr√©tation des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ANALYSE TERMIN√âE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìÅ Livrables disponibles:\")\n",
    "print(\"  ‚Ä¢ livrables/01_ethique.md - Document √©thique\")\n",
    "print(\"  ‚Ä¢ livrables/02_bibliographie.md - Bibliographie\")\n",
    "print(\"  ‚Ä¢ livrables/03_presentation_notebook.ipynb - Ce notebook\")\n",
    "print(\"\\nüíª Code source:\")\n",
    "print(\"  ‚Ä¢ src/data_loader.py - Chargement des donn√©es\")\n",
    "print(\"  ‚Ä¢ src/data_preprocessing.py - Pr√©traitement\")\n",
    "print(\"  ‚Ä¢ src/feature_engineering.py - Feature engineering\")\n",
    "print(\"  ‚Ä¢ src/models.py - Mod√®les ML\")\n",
    "print(\"  ‚Ä¢ src/visualization.py - Visualisations\")\n",
    "print(\"\\nüîó Pour toute question: consultez le README.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
